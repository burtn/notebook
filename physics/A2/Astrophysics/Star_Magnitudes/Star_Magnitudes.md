The brightness of a star (its luminosity) is a measure of how intense the light is. Intensity is defined as the energy per second per unit area at normal incidence on the surface.

Originally stars were classified into 6 brightness categories. 1 being the brightest and 6 being just visible. There are two different terms that are used when talking about brightness. 'apparent magnitude' refers to the brightness of light received from the star whilst 'absolute magnitude' refers to the light emitted by the star. Apparent mangnitudes can be zero or negative as well as positive.

Apparent magnitude is usually given the symbol m in formulae and is measured in a logarithmic scale with each 5 magnitude increase representing 100x more energy per unit area received from the star. 

The absolute magnitude is usually given the symbol M and is defined as the star's apparent magnitude (m) if its location relative to the earth was 10 parsecs.

For any star this can be expressed using the formula:
m - M = 5log(d/10)

This formula is tied to the inverse squate law because we assume that the radiation from the star spreads out evenly in all directions without being absorbed. This makes the intensity I ∝ 1/d².

The formula for one star can be extended to allow comparison between multiple stars star Y and star X with the formula:

my - mx = 2.5log(Ix/Iy)